# B01 AI & LLM Engineering

**æ‰€å±é¢†åŸŸ**: [A05_Spec_Expertise](../readme.md)
**åˆ›å»ºæ—¥æœŸ**: 2026-01-30
**æœ€åæ›´æ–°**: 2026-01-30

## ğŸ“‹ å­é¢†åŸŸå®šä½

AI ä¸å¤§è¯­è¨€æ¨¡å‹å·¥ç¨‹æ˜¯å½“å‰æŠ€æœ¯é¢†åŸŸæœ€çƒ­é—¨å’Œå¿«é€Ÿå‘å±•çš„æ–¹å‘ã€‚ä»æç¤ºå·¥ç¨‹åˆ°æ¨¡å‹å¾®è°ƒï¼Œä» RAG æ¶æ„åˆ° LLM è¿ç»´ï¼Œè¿™ä¸€é¢†åŸŸæ­£åœ¨é‡å¡‘è½¯ä»¶å¼€å‘çš„æ–¹æ–¹é¢é¢ã€‚æŒæ¡ AI å·¥ç¨‹æŠ€èƒ½å·²æˆä¸ºç°ä»£æŠ€æœ¯äººå‘˜çš„å¿…å¤‡èƒ½åŠ›ã€‚

æœ¬é¢†åŸŸæ¶µç›–ä¸‰å¤§æ ¸å¿ƒæ–¹å‘ï¼šæç¤ºå·¥ç¨‹ï¼ˆPrompt Engineeringï¼‰ã€æ¨¡å‹å¾®è°ƒï¼ˆFine-tuningï¼‰å’Œ LLM è¿ç»´ï¼ˆLLMOpsï¼‰ã€‚å·¥ç¨‹å¸ˆéœ€è¦ç†è§£å¤§è¯­è¨€æ¨¡å‹çš„å·¥ä½œåŸç†ï¼ŒæŒæ¡ä¸ AI æ¨¡å‹æœ‰æ•ˆäº¤äº’çš„æŠ€æœ¯ï¼Œä»¥åŠåœ¨ç”Ÿäº§ç¯å¢ƒä¸­éƒ¨ç½²å’Œç»´æŠ¤ AI åº”ç”¨çš„èƒ½åŠ›ã€‚

**æ ¸å¿ƒå…³æ³¨ç‚¹**ï¼š
- **æç¤ºå·¥ç¨‹**: æç¤ºè®¾è®¡æ¨¡å¼ã€Few-shot/Zero-shot å­¦ä¹ ã€é“¾å¼æ€è€ƒã€æç¤ºä¼˜åŒ–
- **æ¨¡å‹å¾®è°ƒ**: PEFTã€LoRAã€QLoRAã€æŒ‡ä»¤å¾®è°ƒã€é¢†åŸŸé€‚åº”
- **LLM è¿ç»´**: æ¨¡å‹éƒ¨ç½²ã€æ¨ç†ä¼˜åŒ–ã€ç›‘æ§ã€æˆæœ¬ç®¡ç†ã€å®‰å…¨å¯¹é½

## ğŸ—‚ï¸ ä¸“é¡¹åˆ—è¡¨

### [C01. Prompt_Engineering](C01_Prompt_Engineering/README.md)

æç¤ºå·¥ç¨‹æ˜¯ä¸å¤§è¯­è¨€æ¨¡å‹æœ‰æ•ˆäº¤äº’çš„è‰ºæœ¯ä¸ç§‘å­¦ã€‚æœ¬ä¸“é¡¹è¯¦è§£æç¤ºè®¾è®¡æ¨¡å¼ï¼ˆZero-shotã€Few-shotã€Chain-of-Thoughtï¼‰ã€æç¤ºä¼˜åŒ–æŠ€æœ¯ï¼ˆè‡ªåŠ¨æç¤ºä¼˜åŒ–ã€A/B æµ‹è¯•ï¼‰ã€ç»“æ„åŒ–è¾“å‡ºï¼ˆJSON/XML æ¨¡å¼ï¼‰ã€ä»¥åŠæç¤ºå®‰å…¨ï¼ˆæç¤ºæ³¨å…¥é˜²æŠ¤ï¼‰ã€‚æ¶µç›– LangChainã€LlamaIndex ç­‰æ¡†æ¶çš„ä½¿ç”¨å’Œæœ€ä½³å®è·µã€‚

### [C02. Model_Fine-Tuning](C02_Model_Fine-Tuning/README.md)

æ¨¡å‹å¾®è°ƒä½¿é¢„è®­ç»ƒæ¨¡å‹é€‚åº”ç‰¹å®šé¢†åŸŸä»»åŠ¡ã€‚æœ¬ä¸“é¡¹æ·±å…¥ PEFTï¼ˆå‚æ•°é«˜æ•ˆå¾®è°ƒï¼‰æŠ€æœ¯ï¼ˆLoRAã€QLoRAã€Adapterï¼‰ã€æŒ‡ä»¤å¾®è°ƒï¼ˆInstruction Tuningï¼‰ã€é¢†åŸŸé€‚åº”ç­–ç•¥ã€ä»¥åŠ RLHFï¼ˆåŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼‰ã€‚æ¶µç›–è®­ç»ƒæ•°æ®å‡†å¤‡ã€è¯„ä¼°æŒ‡æ ‡å’Œæ¨¡å‹åˆå¹¶æŠ€æœ¯ã€‚

### [C03. LLMOps](C03_LLMOps/README.md)

LLMOps æ˜¯åœ¨ç”Ÿäº§ç¯å¢ƒä¸­è¿ç»´å¤§è¯­è¨€æ¨¡å‹åº”ç”¨çš„å®è·µã€‚æœ¬ä¸“é¡¹è¯¦è§£æ¨¡å‹éƒ¨ç½²ç­–ç•¥ï¼ˆvLLMã€TensorRT-LLMã€TGIï¼‰ã€æ¨ç†ä¼˜åŒ–ï¼ˆæ‰¹å¤„ç†ã€é‡åŒ–ã€KV Cacheï¼‰ã€RAG æ¶æ„å®ç°ã€ä»¥åŠ LLM ç›‘æ§ï¼ˆå»¶è¿Ÿã€æˆæœ¬ã€è´¨é‡ã€å®‰å…¨ï¼‰ã€‚æ¶µç›–æ¨¡å‹ç‰ˆæœ¬ç®¡ç†ã€A/B æµ‹è¯•å’Œæˆæœ¬ä¼˜åŒ–ã€‚

## ğŸ› ï¸ æŠ€æœ¯æ ˆæ¦‚è§ˆ

### å¤§è¯­è¨€æ¨¡å‹

| æ¨¡å‹ | æä¾›å•† | ç‰¹ç‚¹ | é“¾æ¥ |
|------|--------|------|------|
| **GPT-4** | OpenAI | æœ€å¼ºç»¼åˆèƒ½åŠ› | https://openai.com/gpt-4 |
| **Claude 3** | Anthropic | é•¿ä¸Šä¸‹æ–‡ï¼Œå®‰å…¨ | https://www.anthropic.com/claude |
| **Gemini** | Google | å¤šæ¨¡æ€ | https://deepmind.google/technologies/gemini |
| **Llama 3** | Meta | å¼€æºé¢†å…ˆ | https://llama.meta.com |
| **Qwen** | Alibaba | ä¸­æ–‡ä¼˜åŒ– | https://qwenlm.github.io |
| **Mistral** | Mistral AI | æ¬§æ´²å¼€æº | https://mistral.ai |

### å¼€å‘æ¡†æ¶

| æ¡†æ¶ | ç”¨é€” | å®˜ç½‘ |
|------|------|------|
| **LangChain** | LLM åº”ç”¨æ¡†æ¶ | https://www.langchain.com |
| **LlamaIndex** | æ•°æ®å¢å¼º LLM | https://www.llamaindex.ai |
| **Hugging Face** | æ¨¡å‹ç”Ÿæ€å¹³å° | https://huggingface.co |
| **Transformers** | æ¨¡å‹åº“ | https://github.com/huggingface/transformers |
| **AutoGen** | å¤šæ™ºèƒ½ä½“æ¡†æ¶ | https://github.com/microsoft/autogen |
| **Langfuse** | LLM å¯è§‚æµ‹æ€§ | https://langfuse.com |

### éƒ¨ç½²ä¸æ¨ç†

| å·¥å…· | ç”¨é€” | å®˜ç½‘ |
|------|------|------|
| **vLLM** | é«˜ååæ¨ç† | https://github.com/vllm-project/vllm |
| **Text Generation Inference** | HuggingFace æ¨ç† | https://github.com/huggingface/text-generation-inference |
| **TensorRT-LLM** | NVIDIA æ¨ç†ä¼˜åŒ– | https://github.com/NVIDIA/TensorRT-LLM |
| **Ollama** | æœ¬åœ°è¿è¡Œ LLM | https://ollama.com |
| **LM Studio** | æ¡Œé¢ LLM ç®¡ç† | https://lmstudio.ai |

## ğŸ’¼ å®è·µæ¡ˆä¾‹ç´¢å¼•

### æ¡ˆä¾‹ 1: RAG çŸ¥è¯†åº“é—®ç­”ç³»ç»Ÿ

**æ¶æ„è®¾è®¡**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     RAG çŸ¥è¯†åº“æ¶æ„                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   æ–‡æ¡£ä¸Šä¼    â”‚â”€â”€â”€â–¶â”‚  æ–‡æ¡£å¤„ç†    â”‚â”€â”€â”€â–¶â”‚  æ–‡æœ¬åˆ†å—    â”‚     â”‚
â”‚  â”‚   (PDF/Doc) â”‚    â”‚  (è§£æ/æ¸…æ´—) â”‚    â”‚  (Chunking) â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                â”‚            â”‚
â”‚                                                â–¼            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   ç”Ÿæˆå›ç­”   â”‚â—€â”€â”€â”€â”‚  LLM å¤„ç†   â”‚â—€â”€â”€â”€â”‚  å‘é‡æ£€ç´¢    â”‚     â”‚
â”‚  â”‚  (Streaming)â”‚    â”‚  (GPT-4)   â”‚    â”‚  (Similarity)â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â–²â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                                â”‚            â”‚
â”‚                              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                              â–¼                              â”‚
â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚                   â”‚    å‘é‡æ•°æ®åº“        â”‚                   â”‚
â”‚                   â”‚  (Pinecone/Milvus)  â”‚                   â”‚
â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**LangChain å®ç°**:
```python
from langchain import OpenAI, VectorDBQA
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import Pinecone
import pinecone

# åˆå§‹åŒ–å‘é‡æ•°æ®åº“
pinecone.init(api_key="...", environment="us-west1-gcp")
embeddings = OpenAIEmbeddings()

# åˆ›å»ºå‘é‡å­˜å‚¨
vectorstore = Pinecone.from_documents(
    documents=chunks,
    embedding=embeddings,
    index_name="knowledge-base"
)

# åˆ›å»º RAG é“¾
qa_chain = VectorDBQA.from_chain_type(
    llm=OpenAI(),
    chain_type="stuff",
    vectorstore=vectorstore,
    return_source_documents=True
)

# æŸ¥è¯¢
result = qa_chain({"query": "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ"})
print(result['result'])
```

### æ¡ˆä¾‹ 2: LoRA æ¨¡å‹å¾®è°ƒ

**å¾®è°ƒæµç¨‹**:
```python
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import LoraConfig, get_peft_model, TaskType
from trl import SFTTrainer

# åŠ è½½åŸºç¡€æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained("meta-llama/Llama-2-7b-hf")
tokenizer = AutoTokenizer.from_pretrained("meta-llama/Llama-2-7b-hf")

# LoRA é…ç½®
lora_config = LoraConfig(
    r=16,  # LoRA rank
    lora_alpha=32,
    target_modules=["q_proj", "v_proj"],
    lora_dropout=0.05,
    bias="none",
    task_type=TaskType.CAUSAL_LM
)

# åº”ç”¨ LoRA
model = get_peft_model(model, lora_config)

# è®­ç»ƒé…ç½®
training_args = TrainingArguments(
    output_dir="./results",
    num_train_epochs=3,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    learning_rate=2e-4,
    fp16=True,
    save_strategy="epoch",
)

# è®­ç»ƒ
trainer = SFTTrainer(
    model=model,
    tokenizer=tokenizer,
    train_dataset=dataset,
    args=training_args,
)
trainer.train()
```

### æ¡ˆä¾‹ 3: LLM ç”Ÿäº§éƒ¨ç½²æ¶æ„

**éƒ¨ç½²æ¶æ„**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    LLM ç”Ÿäº§éƒ¨ç½²æ¶æ„                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  å®¢æˆ·ç«¯                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   Web App   â”‚    â”‚  Mobile App â”‚    â”‚   API è°ƒç”¨  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                  â”‚                  â”‚            â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚                            â–¼                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                 API ç½‘å…³ (Kong/AWS API GW)           â”‚   â”‚
â”‚  â”‚  - é™æµ (Rate Limiting)                              â”‚   â”‚
â”‚  â”‚  - è®¤è¯ (API Key/JWT)                               â”‚   â”‚
â”‚  â”‚  - ç¼“å­˜å“åº”                                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                            â–¼                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              è´Ÿè½½å‡è¡¡å™¨ (NGINX/ALB)                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                            â–¼                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              LLM æ¨ç†æœåŠ¡ (vLLM/TGI)                  â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚  Instance 1 â”‚  â”‚  Instance 2 â”‚  â”‚  Instance N â”‚  â”‚   â”‚
â”‚  â”‚  â”‚  (GPU A10)  â”‚  â”‚  (GPU A10)  â”‚  â”‚  (GPU A10)  â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                            â”‚                                â”‚
â”‚                            â–¼                                â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚               ç›‘æ§ä¸å¯è§‚æµ‹æ€§                          â”‚   â”‚
â”‚  â”‚  - Prometheus (æŒ‡æ ‡)                                 â”‚   â”‚
â”‚  â”‚  - Grafana (å¯è§†åŒ–)                                  â”‚   â”‚
â”‚  â”‚  - Langfuse (LLM è¿½è¸ª)                               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”— çŸ¥è¯†å…³è”å›¾è°±

```mermaid
graph TB
    B[B01 AI LLM Engineering]
    
    %% åŒå±‚å…³è”
    B -->|3D/æ¸²æŸ“| B02[A05/B02 Graphics 3D<br/>å›¾å½¢3D]
    B -->|æœºå™¨äººAI| B03[A05/B03 Robotics ROS<br/>æœºå™¨äºº]
    B -->|æœªæ¥æŠ€æœ¯| B04[A05/B04 Future Tech<br/>æœªæ¥æŠ€æœ¯]
    
    %% ä¸“é¡¹å…³è”
    B --> C01[C01 Prompt Engineering]
    B --> C02[C02 Model Fine-Tuning]
    B --> C03[C03 LLMOps]
    
    C01 -->|æç¤ºä¼˜åŒ–éœ€è¦ç†è§£æ¨¡å‹| C02
    C02 -->|å¾®è°ƒé…æ¶‰åŠéƒ¨ç½²| C03
    C01 -->|ç”Ÿäº§æç¤ºç®¡ç†| C03
    
    %% è·¨å±‚å…³è”
    B -.->|AIåŸºç¡€è®¾æ–½| A01[A01 Infrastructure<br/>åŸºç¡€è®¾æ–½]
    B -.->|AIå®‰å…¨| A04[A04 Security Quality<br/>å®‰å…¨è´¨é‡]
    B -.->|AIæ¶æ„| A03[A03 Design Architecture<br/>æ¶æ„è®¾è®¡]
```

## ğŸ“– å­¦ä¹ èµ„æº

### æ¨èä¹¦ç±

| ä¹¦å | ä½œè€… | è¯´æ˜ |
|------|------|------|
| ã€ŠHands-On Large Language Modelsã€‹ | Jay Alammar | LLM å®è·µæŒ‡å— |
| ã€ŠBuilding LLM Applicationsã€‹ |  | LLM åº”ç”¨å¼€å‘ |
| ã€ŠNatural Language Processing with Transformersã€‹ | Lewis et al. | Transformers è¯¦è§£ |
| ã€ŠDesigning Machine Learning Systemsã€‹ | Chip Huyen | ML ç³»ç»Ÿè®¾è®¡ |

### åœ¨çº¿è¯¾ç¨‹

| è¯¾ç¨‹ | å¹³å° | é“¾æ¥ |
|------|------|------|
| DeepLearning.AI LLM è¯¾ç¨‹ | Coursera | https://www.deeplearning.ai/short-courses/ |
| Fast.ai å®ç”¨æ·±åº¦å­¦ä¹  | fast.ai | https://course.fast.ai |
| Stanford CS224N | Stanford | https://web.stanford.edu/class/cs224n |
| Full Stack LLM Bootcamp | Full Stack Deep Learning | https://fullstackdeeplearning.com/llm-bootcamp |

### æŠ€æœ¯èµ„æº

| èµ„æº | é“¾æ¥ | è¯´æ˜ |
|------|------|------|
| Prompt Engineering Guide | https://www.promptingguide.ai | æç¤ºå·¥ç¨‹æŒ‡å— |
| Hugging Face Transformers | https://huggingface.co/docs/transformers | å®˜æ–¹æ–‡æ¡£ |
| LangChain Docs | https://python.langchain.com | LangChain æ–‡æ¡£ |
| OpenAI Cookbook | https://github.com/openai/openai-cookbook | OpenAI ç¤ºä¾‹ |
| Papers with Code | https://paperswithcode.com | æœ€æ–°è®ºæ–‡ |

### å¼€æºé¡¹ç›®

| é¡¹ç›® | GitHub | è¯´æ˜ |
|------|--------|------|
| Transformers | https://github.com/huggingface/transformers | æ¨¡å‹åº“ |
| LangChain | https://github.com/langchain-ai/langchain | åº”ç”¨æ¡†æ¶ |
| LlamaIndex | https://github.com/run-llama/llama_index | æ•°æ®å¢å¼º |
| vLLM | https://github.com/vllm-project/vllm | é«˜ååæ¨ç† |
| Ollama | https://github.com/ollama/ollama | æœ¬åœ°è¿è¡Œ |
| OpenWebUI | https://github.com/open-webui/open-webui | Web UI |

## ğŸ”„ ç»´æŠ¤è¯´æ˜

- **å†…å®¹å®¡æŸ¥**: æ¯æœˆæ›´æ–°æ¨¡å‹ä¿¡æ¯å’Œå·¥å…·ç‰ˆæœ¬
- **æ›´æ–°æœºåˆ¶**: è·Ÿè¸ª arXivã€HuggingFace å’Œå‚å•†å‘å¸ƒ
- **è´¨é‡æ ‡å‡†**: æ‰€æœ‰ä»£ç ç¤ºä¾‹éœ€æµ‹è¯•éªŒè¯
- **è´¡çŒ®æ–¹å¼**: æ¬¢è¿æäº¤å¾®è°ƒæ¡ˆä¾‹å’Œéƒ¨ç½²ç»éªŒ
